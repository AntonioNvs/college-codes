{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP1 - PLN\n",
    "\n",
    "**Nome:** Antônio Caetano Neves Neto\n",
    "\n",
    "**Matrícula:** 2022043698"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras para teste: 19374\n"
     ]
    }
   ],
   "source": [
    "with open(\"files/questions-words.txt\", \"r\") as src:\n",
    "    lines = src.read().split(\"\\n\")\n",
    "\n",
    "    section = lines[0].split(\" \")[1]\n",
    "\n",
    "    test_per_section = {section: []}\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if \":\" in line:\n",
    "            section = line.split(\" \")[1]\n",
    "            test_per_section[section] = []\n",
    "        else:\n",
    "            test_per_section[section].append(line)\n",
    "\n",
    "    words_for_test = set(np.concatenate([tests for tests in test_per_section.values()]).tolist())\n",
    "print(f\"Número de palavras para teste: {len(words_for_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = \"files/embedding.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding():\n",
    "    embedding = {}\n",
    "    with open(embedding_file, \"r\") as src:\n",
    "        lines = src.read().split(\"\\n\")\n",
    "\n",
    "        n_lines, k = [int(w) for w in lines[0].split(\" \")]\n",
    "\n",
    "        for line in lines[1:]:\n",
    "            w = line.strip().split(\" \")\n",
    "            embedding[w[0]] = np.array([float(n) for n in w[1:]])\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_of_word(word, embedding):\n",
    "  if word not in embedding:\n",
    "    return embedding[\"</s>\"]\n",
    "  return embedding[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "  dot_product = np.dot(v1, v2)\n",
    "  norm_v1 = np.linalg.norm(v1)\n",
    "  norm_v2 = np.linalg.norm(v2)\n",
    "  if norm_v1 == 0 or norm_v2 == 0:\n",
    "    return 0\n",
    "  return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "def cosine_distance(v1, v2):\n",
    "  return 1 - cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(embedding):\n",
    "    results = {}\n",
    "    for section, tests in test_per_section.items():\n",
    "        cosine_distances = []\n",
    "\n",
    "        for test in tests:\n",
    "            if len(test.lower().split(\" \")) != 4: continue\n",
    "\n",
    "            word1, word2, word3, word4 = test.lower().split(\" \")\n",
    "\n",
    "            v = get_embedding_of_word(word1, embedding) + get_embedding_of_word(word2, embedding) - get_embedding_of_word(word3, embedding)\n",
    "\n",
    "            cosine_distances.append(\n",
    "                cosine_distance(v, get_embedding_of_word(word4, embedding))\n",
    "            )\n",
    "\n",
    "        results[section] = (np.mean(cosine_distances), np.std(cosine_distances))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start CBOW-3-50-3 configuration..\n",
      "\n",
      "Starting training using file files/context.txt\n",
      "Vocab size: 71291\n",
      "Words in train file: 16718843\n",
      "Alpha: 0.000005  Progress: 100.01%  Words/thread/sec: 354.40k  \n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for strategy in [\"CBOW\", \"Skip-gram\"]:\n",
    "    for window_size in [3, 5, 10, 20]:\n",
    "        for embedding_size in [50, 100, 150]:\n",
    "            for n_iter in [3, 5, 10]:\n",
    "                configuration = f\"{strategy}-{str(window_size)}-{str(embedding_size)}-{str(n_iter)}\"\n",
    "                print(f\"Start {configuration} configuration..\", end=\"\\n\\n\")\n",
    "\n",
    "                os.system(\n",
    "                    f\"./word2vec/word2vec -train files/context.txt -output files/embedding.txt -size {embedding_size} -window {window_size} -iter {n_iter} -cbow {int(strategy == 'CBOW')} -threads 4\"\n",
    "                )\n",
    "                \n",
    "                embedding = get_embedding()\n",
    "                results[configuration] = validate(embedding)\n",
    "                print()\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW-3-50-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>capital-common-countries</th>\n",
       "      <td>(0.6579326547912443, 0.21777780325830695)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-world</th>\n",
       "      <td>(0.5098990135979198, 0.28979038516735267)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city-in-state</th>\n",
       "      <td>(0.4255234578439494, 0.21047971117336192)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>(0.9435725391048057, 0.1449417705893463)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>(1.0250782276835824, 0.4670104677947348)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram1-adjective-to-adverb</th>\n",
       "      <td>(1.044039981024375, 0.24828086566864788)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram2-opposite</th>\n",
       "      <td>(1.0525152264409972, 0.2827792842439299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram3-comparative</th>\n",
       "      <td>(0.8807827041723958, 0.24474101837219994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram4-superlative</th>\n",
       "      <td>(1.0533373626265128, 0.24164052646143327)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram5-present-participle</th>\n",
       "      <td>(1.1410245329992625, 0.2841799705798426)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram6-nationality-adjective</th>\n",
       "      <td>(0.8383806664446449, 0.21837794896387044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram7-past-tense</th>\n",
       "      <td>(1.0118593943933087, 0.27281598362554277)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram8-plural</th>\n",
       "      <td>(1.0525825991758706, 0.319263401595593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gram9-plural-verbs</th>\n",
       "      <td>(1.1376734121817702, 0.2533505761718939)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           CBOW-3-50-3\n",
       "capital-common-countries     (0.6579326547912443, 0.21777780325830695)\n",
       "capital-world                (0.5098990135979198, 0.28979038516735267)\n",
       "city-in-state                (0.4255234578439494, 0.21047971117336192)\n",
       "currency                      (0.9435725391048057, 0.1449417705893463)\n",
       "family                        (1.0250782276835824, 0.4670104677947348)\n",
       "gram1-adjective-to-adverb     (1.044039981024375, 0.24828086566864788)\n",
       "gram2-opposite                (1.0525152264409972, 0.2827792842439299)\n",
       "gram3-comparative            (0.8807827041723958, 0.24474101837219994)\n",
       "gram4-superlative            (1.0533373626265128, 0.24164052646143327)\n",
       "gram5-present-participle      (1.1410245329992625, 0.2841799705798426)\n",
       "gram6-nationality-adjective  (0.8383806664446449, 0.21837794896387044)\n",
       "gram7-past-tense             (1.0118593943933087, 0.27281598362554277)\n",
       "gram8-plural                   (1.0525825991758706, 0.319263401595593)\n",
       "gram9-plural-verbs            (1.1376734121817702, 0.2533505761718939)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
